{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralNetwoork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcosRolando/OrgaDeDatosTP2/blob/main/neuralNetwoork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGS8tOq2uIJn"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from tensorflow import feature_column\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxVjrxBo5slK"
      },
      "source": [
        "df = pd.read_csv('/content/Train_TP2_Datos_2020-2C.csv')\r\n",
        "df = df[df['Stage'].isin(['Closed Won', 'Closed Lost'])]\r\n",
        "df.loc[:, 'Stage'].replace({'Closed Won':1, 'Closed Lost':0}, inplace=True) #0 corresponde a que el caso fue Closed Lost, 1 a que fue Closed Won. Asi tenemos un problema de clasificacion binario que puede entender la red neuronal.\r\n",
        "\r\n",
        "df.loc[:, 'Planned_Delivery_Start_Date'] = pd.to_datetime(df['Planned_Delivery_Start_Date'], 'coerce',\r\n",
        "                                                                format='%m/%d/%Y')\r\n",
        "df.loc[:, 'Planned_Delivery_End_Date'] = pd.to_datetime(df['Planned_Delivery_End_Date'], 'coerce',\r\n",
        "                                                                                    format='%m/%d/%Y')\r\n",
        "df = df[df['Opportunity_ID'] != 9773] #Hardcodeo este filtrado porque el id 9773 tiene mal cargada la fecha de delviery end, dando una diferencia de 200 anios xd\"\r\n",
        "\r\n",
        "#Pongo .loc porque pandas me jode con warnings que son falsos positivos de slice copy\"\r\n",
        "#Gracias Pandas!\"\r\n",
        "\r\n",
        "#Creamos una nueva columna (Feature Engineering) que contiene la longitud en dias \r\n",
        "#estimada de la operacion. En el informe habiamos encontrado que aparentaba haber\r\n",
        "#una relacion cuadratica de decrecimiento a medida que aumentaban los dias donde disminuia\r\n",
        "#la chance de completar la operacion.\r\n",
        "df['Delta_Time'] = df['Planned_Delivery_End_Date'] - df['Planned_Delivery_Start_Date']\r\n",
        "df.loc[:, 'Delta_Time'] = df['Delta_Time'].dt.days"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "rNFq-F-xroWZ",
        "outputId": "e8476a7d-12d7-4b13-a580-441c4b219d85"
      },
      "source": [
        "\r\n",
        "#Borro columnas que tengan el mismo dato en todas las entradas, o inconsecuentes como el ID / Opportunity_ID\r\n",
        "#Algunas columnas borradas son porque pienso que no tienen incidencia, ir viendo.\r\n",
        "#TODO: Analizar si el Sales_Contract_No no es que importe el numero en si, sino si tiene\r\n",
        "#o no tiene numero de contrato. Por ahora no lo meto como input.\r\n",
        "#TODO: Ver el mismo tema con la columna 'Price', la mayoria tiene None u Other\r\n",
        "#y solo unos pocos tienen precio numerico. Quiza importe que tenga precio o no tenga,\r\n",
        "#o si no tiene precio quiza importe si es None u Other. Por ahora no lo pongo\r\n",
        "#como input.\r\n",
        "df.drop(columns=['Submitted_for_Approval', 'Last_Activity', 'ASP_(converted)_Currency', \r\n",
        "                 'Prod_Category_A', 'ID', 'Opportunity_ID', 'Sales_Contract_No',\r\n",
        "                 'Price','ASP','ASP_Currency','Total_Amount_Currency','Total_Amount'],inplace=True)\r\n",
        "\r\n",
        "#Renombramos las columnas que tienen caracteres que TensorFlow no acepta como validos.\r\n",
        "#Estos particularmente son whitespace, coma y parentesis por ejemplo.\r\n",
        "df.rename(columns={'ASP_(converted)':'ASP_converted','Pricing, Delivery_Terms_Quote_Appr':\r\n",
        "                   'Pricing_Delivery_Terms_Quote_Appr','Pricing, Delivery_Terms_Approved':\r\n",
        "                   'Pricing_Delivery_Terms_Approved','Source ':'Source'},inplace=True)\r\n",
        "\r\n",
        "#Columnas que consideramos numericas\r\n",
        "numeric_columns = ['Pricing_Delivery_Terms_Quote_Appr','Pricing_Delivery_Terms_Approved',\r\n",
        "                     'Bureaucratic_Code_0_Approval','Bureaucratic_Code_0_Approved',\r\n",
        "                     'ASP_converted','TRF','Total_Amount','Total_Taxable_Amount']\r\n",
        "\r\n",
        "#Columnas que consideramos clasificatorias con rango numerico\r\n",
        "bucketized_columns = ['Delta_Time']\r\n",
        "\r\n",
        "#Columnas que consideramos categoricas de pocos valores posibles\r\n",
        "indicator_columns = ['Region','Territory','Bureaucratic_Code','Source',\r\n",
        "                       'Billing_Country','Account_Name','Opportunity_Name',\r\n",
        "                       'Account_Owner','Opportunity_Owner','Account_Type',\r\n",
        "                       'Opportunity_Type','Quote_Type','Delivery_Terms',\r\n",
        "                       'Brand','Product_Type','Size','Product_Category_B',\r\n",
        "                       'Currency','Last_Modified_By','Product_Family',\r\n",
        "                       'Product_Name','Total_Amount_Currency',\r\n",
        "                       'Total_Taxable_Amount_Currency']\r\n",
        "\r\n",
        "#Drop columnas que vamos a usar pero por ahora no las uso\r\n",
        "df.drop(columns=['Account_Created_Date','Opportunity_Created_Date',\r\n",
        "                 'Quote_Expiry_Date','Last_Modified_Date',\r\n",
        "                 'Planned_Delivery_Start_Date','Planned_Delivery_End_Date',\r\n",
        "                 'Month','Delivery_Quarter', 'Delivery_Year', 'Actual_Delivery_Date'],inplace=True)\r\n",
        "\r\n",
        "#Debemos separar algunos de los registros para armar un set de test propio (no el de la catedra). De esta forma sabremos rapidamente\r\n",
        "#si nuestro modelo esta dando resultados optimos o no sin necesidad de estar subiendo el TP a Kaggle constantemente.\r\n",
        "#Sin embargo, no queremos usar tantos registros ya que estariamos disminuyendo el set de entrenamiento considerablemente.\r\n",
        "#Podemos empezar reservando 2000 registros para el test de prueba y ver que onda. Pasariamos de tener 16 mil a 14 mil \r\n",
        "#registros para el set de entrenamiento, no es una perdida importantisima creo en principio, asi que arrancamos con eso.\r\n",
        "\r\n",
        "#Por otro lado, nuestro test de prueba deberia tener un 50 50 de Closed Won y Closed Lost, por lo que no podemos elegir asi nomas\r\n",
        "#al azar.\r\n",
        "\r\n",
        "#TODO: DEJO COMO TAREA ARMAR EL SET DE PRUEBA, POR AHORA SOLO NOS PREOCUPAMOS DE LOGRAR HACER ANDAR LA RED NEURONAL.\r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Region</th>\n",
              "      <th>Territory</th>\n",
              "      <th>Pricing_Delivery_Terms_Quote_Appr</th>\n",
              "      <th>Pricing_Delivery_Terms_Approved</th>\n",
              "      <th>Bureaucratic_Code_0_Approval</th>\n",
              "      <th>Bureaucratic_Code_0_Approved</th>\n",
              "      <th>Bureaucratic_Code</th>\n",
              "      <th>Source</th>\n",
              "      <th>Billing_Country</th>\n",
              "      <th>Account_Name</th>\n",
              "      <th>Opportunity_Name</th>\n",
              "      <th>Account_Owner</th>\n",
              "      <th>Opportunity_Owner</th>\n",
              "      <th>Account_Type</th>\n",
              "      <th>Opportunity_Type</th>\n",
              "      <th>Quote_Type</th>\n",
              "      <th>Delivery_Terms</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Product_Type</th>\n",
              "      <th>Size</th>\n",
              "      <th>Product_Category_B</th>\n",
              "      <th>Currency</th>\n",
              "      <th>Last_Modified_By</th>\n",
              "      <th>Product_Family</th>\n",
              "      <th>Product_Name</th>\n",
              "      <th>ASP_converted</th>\n",
              "      <th>TRF</th>\n",
              "      <th>Total_Amount_Currency</th>\n",
              "      <th>Total_Amount</th>\n",
              "      <th>Total_Taxable_Amount_Currency</th>\n",
              "      <th>Total_Taxable_Amount</th>\n",
              "      <th>Stage</th>\n",
              "      <th>Delta_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EMEA</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bureaucratic_Code_4</td>\n",
              "      <td>None</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>Account_Name_619</td>\n",
              "      <td>Opportunity_Name_12598</td>\n",
              "      <td>Person_Name_51</td>\n",
              "      <td>Person_Name_18</td>\n",
              "      <td>Account_Type_2</td>\n",
              "      <td>Opportunity_Type_1</td>\n",
              "      <td>Non Binding</td>\n",
              "      <td>Delivery_Terms_2</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Person_Name_18</td>\n",
              "      <td>Product_Family_77</td>\n",
              "      <td>Product_Name_99</td>\n",
              "      <td>0.58817</td>\n",
              "      <td>10</td>\n",
              "      <td>EUR</td>\n",
              "      <td>5272800.0</td>\n",
              "      <td>EUR</td>\n",
              "      <td>5272800.0</td>\n",
              "      <td>0</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EMEA</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bureaucratic_Code_4</td>\n",
              "      <td>None</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>Account_Name_619</td>\n",
              "      <td>Opportunity_Name_12600</td>\n",
              "      <td>Person_Name_51</td>\n",
              "      <td>Person_Name_20</td>\n",
              "      <td>Account_Type_2</td>\n",
              "      <td>Opportunity_Type_1</td>\n",
              "      <td>Non Binding</td>\n",
              "      <td>Delivery_Terms_2</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Person_Name_20</td>\n",
              "      <td>Product_Family_77</td>\n",
              "      <td>Product_Name_100</td>\n",
              "      <td>0.59948</td>\n",
              "      <td>0</td>\n",
              "      <td>EUR</td>\n",
              "      <td>48230.0</td>\n",
              "      <td>EUR</td>\n",
              "      <td>48230.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Americas</td>\n",
              "      <td>NW America</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bureaucratic_Code_4</td>\n",
              "      <td>Source_7</td>\n",
              "      <td>United States</td>\n",
              "      <td>Account_Name_1794</td>\n",
              "      <td>Opportunity_Name_469</td>\n",
              "      <td>Person_Name_64</td>\n",
              "      <td>Person_Name_8</td>\n",
              "      <td>Account_Type_5</td>\n",
              "      <td>Opportunity_Type_1</td>\n",
              "      <td>Non Binding</td>\n",
              "      <td>Delivery_Terms_4</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Person_Name_8</td>\n",
              "      <td>Product_Family_81</td>\n",
              "      <td>Product_Name_91</td>\n",
              "      <td>0.48000</td>\n",
              "      <td>0</td>\n",
              "      <td>USD</td>\n",
              "      <td>83865.6</td>\n",
              "      <td>USD</td>\n",
              "      <td>83865.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Americas</td>\n",
              "      <td>NW America</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Bureaucratic_Code_5</td>\n",
              "      <td>Source_11</td>\n",
              "      <td>United States</td>\n",
              "      <td>Account_Name_1201</td>\n",
              "      <td>Opportunity_Name_415</td>\n",
              "      <td>Person_Name_8</td>\n",
              "      <td>Person_Name_8</td>\n",
              "      <td>Account_Type_5</td>\n",
              "      <td>Opportunity_Type_19</td>\n",
              "      <td>Non Binding</td>\n",
              "      <td>Delivery_Terms_1</td>\n",
              "      <td>Other</td>\n",
              "      <td>Product_Type_0</td>\n",
              "      <td>Size_4</td>\n",
              "      <td>Product_Category_B_16</td>\n",
              "      <td>USD</td>\n",
              "      <td>Person_Name_8</td>\n",
              "      <td>Product_Family_209</td>\n",
              "      <td>Product_Name_432</td>\n",
              "      <td>0.53000</td>\n",
              "      <td>14</td>\n",
              "      <td>USD</td>\n",
              "      <td>7421881.5</td>\n",
              "      <td>USD</td>\n",
              "      <td>7421881.5</td>\n",
              "      <td>0</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Americas</td>\n",
              "      <td>NW America</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Bureaucratic_Code_5</td>\n",
              "      <td>Source_11</td>\n",
              "      <td>United States</td>\n",
              "      <td>Account_Name_1201</td>\n",
              "      <td>Opportunity_Name_851</td>\n",
              "      <td>Person_Name_8</td>\n",
              "      <td>Person_Name_8</td>\n",
              "      <td>Account_Type_5</td>\n",
              "      <td>Opportunity_Type_19</td>\n",
              "      <td>Non Binding</td>\n",
              "      <td>Delivery_Terms_1</td>\n",
              "      <td>Other</td>\n",
              "      <td>Product_Type_0</td>\n",
              "      <td>Size_4</td>\n",
              "      <td>Product_Category_B_16</td>\n",
              "      <td>USD</td>\n",
              "      <td>Person_Name_8</td>\n",
              "      <td>Product_Family_209</td>\n",
              "      <td>Product_Name_432</td>\n",
              "      <td>0.53000</td>\n",
              "      <td>25</td>\n",
              "      <td>USD</td>\n",
              "      <td>13357192.5</td>\n",
              "      <td>USD</td>\n",
              "      <td>13357192.5</td>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Region   Territory  ...  Stage  Delta_Time\n",
              "0      EMEA        None  ...      0        60.0\n",
              "1      EMEA        None  ...      1         2.0\n",
              "2  Americas  NW America  ...      1         0.0\n",
              "3  Americas  NW America  ...      0        58.0\n",
              "4  Americas  NW America  ...      0        27.0\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjY1dvgAdSzw"
      },
      "source": [
        "# Metodo que pasa de DataFrame de Pandas a un DataSet de TensorFlow\r\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\r\n",
        "  dataframe = dataframe.copy()\r\n",
        "  labels = dataframe.pop('Stage') #Retorna la columna Stage, eliminandolo simultaneamente del DataFrame. 'Stage' seria nuestra columna 'target', es decir, lo que queremos predecir.\r\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels)) #Crea un DataSet cuyos elementos son slices de los tensores pasados a la funcion. Ver documentacion oficial para comprender bien.\r\n",
        "  #En pocas palabras, le pasamos las columnas con los datos como diccionario (estilo 'columna':[dato1,dato2,dato3]) y una lista con los resultados estilo [resu1,resu2,resu3].\r\n",
        "  #Se genera un DataSet del estilo [('columna':[dato1,dato2,dato3], [resu1, resu2, resu3])].\r\n",
        "  #En realidad 'columna' es una lista de todas las columnas con sus correspondientes datos, pero se entiende la idea creo.\r\n",
        "  if shuffle:\r\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe)) #Al tener el buffer_size del mismo tamanio que la cantidad de datos del dataset, tenemos perfect shuffling (ver documentacion para comprender).\r\n",
        "    #Basicamente mezlcamos el dataset para que luego los batches que se armen contengan distintos elementos si lo entrenamos distintas veces.\r\n",
        "  ds = ds.batch(batch_size) #Arma batches de tamanio batch_size entre elementos consecutivos del DataSet.\r\n",
        "  return ds"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmaiJcl39e7X"
      },
      "source": [
        "#Arma las features, asignando las columnas del DataFrame segun corresponda al tipo de feature\r\n",
        "#(numerico, categorico, etc). Entiendase por feature a las columnas del DataFrame.\r\n",
        "def set_up_feature_columns(dataframe, numeric_columns, indicator_columns):\r\n",
        "  features = []\r\n",
        "\r\n",
        "  #numeric features\r\n",
        "  for column_name in numeric_columns:\r\n",
        "    features.append(feature_column.numeric_column(column_name))\r\n",
        "\r\n",
        "  # bucketized cols\r\n",
        "  boundaries = []\r\n",
        "  for i in range(35):\r\n",
        "    boundaries.append(i*10.0)\r\n",
        "\r\n",
        "  estimatedOpportunityTimeLapse = feature_column.numeric_column('Delta_Time')\r\n",
        "  time_buckets = feature_column.bucketized_column(estimatedOpportunityTimeLapse, \r\n",
        "                                                  boundaries)\r\n",
        "  features.append(time_buckets)\r\n",
        "\r\n",
        "  # indicator_columns (one-hot value vector, para aquellas columnas categoricas de pocas opciones)\r\n",
        "  for column_name in indicator_columns:\r\n",
        "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\r\n",
        "                                          column_name, dataframe[column_name].unique())\r\n",
        "    indicator_column = feature_column.embedding_column(categorical_column, dimension=8)\r\n",
        "    features.append(indicator_column)\r\n",
        "\r\n",
        "  return features"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0gHFhmD-AbE"
      },
      "source": [
        "Preparamos los features para el modelo, es decir, seteamos cada una de las columnas que vayamos a utilizar del DataFrame. Luego generamos el DataSet en base al DataFrame para darselo como input al modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bTkNirdLlCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd0271c-99f9-489b-e2d9-88492f73470f"
      },
      "source": [
        "  features = set_up_feature_columns(df,numeric_columns,indicator_columns)\r\n",
        "  feature_layer = tf.keras.layers.DenseFeatures(features)\r\n",
        "  ds = df_to_dataset(df,batch_size=32)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 20.0, 40.0, 60.0, 80.0, 100.0, 120.0, 140.0, 160.0, 180.0, 200.0, 220.0, 240.0, 260.0, 280.0, 300.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgLC9fhu-Mqu"
      },
      "source": [
        "Creamos y compilamos el modelo. En esta seccion se tunean las propiedades del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgXH6i3kL9ZN"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "  feature_layer,\r\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\r\n",
        "  tf.keras.layers.Dense(512,activation='relu'),\r\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\r\n",
        "  tf.keras.layers.Dense(512,activation='relu'),\r\n",
        "  tf.keras.layers.Dropout(0.1),\r\n",
        "  tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stA0Y5lI9-Jy"
      },
      "source": [
        "Entrenamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6px_EtjoYRXq",
        "outputId": "ff2cbfc5-1bd2-479b-ed1f-c3091b7cba5f"
      },
      "source": [
        "#Ignoren el WARNING, esta en la documentacion tambien. Nadie le da bola en StackOverflow xd.\r\n",
        "model.fit(ds,epochs=150)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Region': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Territory': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'Pricing_Delivery_Terms_Quote_Appr': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=int64>, 'Pricing_Delivery_Terms_Approved': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=int64>, 'Bureaucratic_Code_0_Approval': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=int64>, 'Bureaucratic_Code_0_Approved': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=int64>, 'Bureaucratic_Code': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'Source': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'Billing_Country': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=string>, 'Account_Name': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'Opportunity_Name': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'Account_Owner': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'Opportunity_Owner': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>, 'Account_Type': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=string>, 'Opportunity_Type': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=string>, 'Quote_Type': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=string>, 'Delivery_Terms': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'Brand': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=string>, 'Product_Type': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'Size': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Product_Category_B': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=string>, 'Currency': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'Last_Modified_By': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>, 'Product_Family': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=string>, 'Product_Name': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=string>, 'ASP_Currency': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'ASP': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'ASP_converted': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'TRF': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=int64>, 'Total_Amount_Currency': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=string>, 'Total_Amount': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float64>, 'Total_Taxable_Amount_Currency': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=string>, 'Total_Taxable_Amount': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float64>, 'Delta_Time': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Region': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Territory': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'Pricing_Delivery_Terms_Quote_Appr': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=int64>, 'Pricing_Delivery_Terms_Approved': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=int64>, 'Bureaucratic_Code_0_Approval': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=int64>, 'Bureaucratic_Code_0_Approved': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=int64>, 'Bureaucratic_Code': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'Source': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'Billing_Country': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=string>, 'Account_Name': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'Opportunity_Name': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'Account_Owner': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'Opportunity_Owner': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>, 'Account_Type': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=string>, 'Opportunity_Type': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=string>, 'Quote_Type': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=string>, 'Delivery_Terms': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'Brand': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=string>, 'Product_Type': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'Size': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Product_Category_B': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=string>, 'Currency': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'Last_Modified_By': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>, 'Product_Family': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=string>, 'Product_Name': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=string>, 'ASP_Currency': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'ASP': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'ASP_converted': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'TRF': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=int64>, 'Total_Amount_Currency': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=string>, 'Total_Amount': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float64>, 'Total_Taxable_Amount_Currency': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=string>, 'Total_Taxable_Amount': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float64>, 'Delta_Time': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "132/132 [==============================] - 3s 12ms/step - loss: 8.7291 - accuracy: 0.4340\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.7234 - accuracy: 0.4345\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6551 - accuracy: 0.4389\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6747 - accuracy: 0.4376\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.8157 - accuracy: 0.4285\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6799 - accuracy: 0.4373\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.7673 - accuracy: 0.4316\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.7721 - accuracy: 0.4313\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.7452 - accuracy: 0.4331\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6662 - accuracy: 0.4382\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6604 - accuracy: 0.4385\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.7203 - accuracy: 0.4347\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.5802 - accuracy: 0.4437\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6904 - accuracy: 0.4366\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.7764 - accuracy: 0.4310\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6983 - accuracy: 0.4361\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.7099 - accuracy: 0.4353\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6518 - accuracy: 0.4391\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6933 - accuracy: 0.4364\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 8.6748 - accuracy: 0.4376\n",
            "Epoch 21/200\n",
            " 56/132 [===========>..................] - ETA: 0s - loss: 8.8380 - accuracy: 0.4270"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-83fbb8fa8698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Ignoren el WARNING, esta en la documentacion tambien. Nadie le da bola en StackOverflow xd.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYTFqZSM-TA-"
      },
      "source": [
        "Evaluamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SDVpkRXMmLD"
      },
      "source": [
        "loss, accuracy = model.evaluate(ds)\r\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}